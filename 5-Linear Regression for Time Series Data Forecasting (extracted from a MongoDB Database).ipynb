{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36208c-d414-4871-80f4-970c03d3a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from pprint import PrettyPrinter\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from pymongo import MongoClient\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.ar_model import AutoReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc749ff-c127-443a-b6fe-ffc79f4f536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to MongoDB and extracting the collection \"dar-es-salaam\"\n",
    "client = MongoClient(host=\"localhost\", port= 27017)\n",
    "db = client[\"air-quality\"]\n",
    "dar = db[\"dar-es-salaam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4f7f6-e811-491d-aa33-88560bb53bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up PrettyPrinter, a tool to print the collections from MongoDB in order to get familiar with the db\n",
    "pp= PrettyPrinter(indent=2)\n",
    "result = dar.find_one({})\n",
    "pp.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5353b7-0a19-4a3e-adef-d2573e2a4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this command we will know how many distinct sites there are\n",
    "sites = dar.distinct(\"metadata.site\")\n",
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb1ea7-1c84-4963-b494-4fa81759766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation to obtain the id of the sites and their counts \n",
    "result = dar.aggregate(\n",
    "    [\n",
    "        {\"$group\": {\"_id\": \"$metadata.site\", \"count\": {\"$count\": {}}}}\n",
    "    ]\n",
    ")\n",
    "readings_per_site = list(result)\n",
    "readings_per_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde66a5-601c-4789-b406-6ddd15557e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a wrangle function to perform different transformations to the data in order to work with it\n",
    "def wrangle(collection):\n",
    "    results = collection.find(\n",
    "        {\"metadata.site\": 11, \"metadata.measurement\": \"P2\"},\n",
    "        projection={\"P2\": 1, \"timestamp\": 1, \"_id\": 0},\n",
    "    )\n",
    "\n",
    "    # Read results into DataFrame\n",
    "    df = pd.DataFrame(list(results)).set_index(\"timestamp\")\n",
    "\n",
    "    # Localize timezone\n",
    "    df.index = df.index.tz_localize(\"UTC\").tz_convert(\"Africa/Dar_es_Salaam\")\n",
    "\n",
    "    # Remove outliers\n",
    "    df = df[df[\"P2\"] < 100]\n",
    "    \n",
    "    # Resample and forward-fill\n",
    "    y = df[\"P2\"].resample(\"1H\").mean().fillna(method=\"ffill\")\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e2478-0d89-4724-9bc3-930d6a3417b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's all the registers from the dar collection, cleaned\n",
    "y = wrangle(dar)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2ee6b-c4f6-433b-bea9-c075438723ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a time series plot with the data from y\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "y.plot(xlabel= \"Date\", ylabel=\"PM2.5 Level\", title= \"Dar es Salaam PM2.5 Levels\", ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f1f39-06f9-46fd-a543-da19a9e57940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling average time series plot \n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "y.rolling(168).mean().plot(ax=ax, ylabel=\"PM2.5\", title=\"Weekly Rolling Average\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9320b28-a127-482c-b736-c2f31153e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF plot to check the autocorrelation of the lags\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_acf(y, ax=ax)\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24b921-1d3e-4e0f-9b8d-9f62546eed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial ACF to understand better the autocorrelation of the lags\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_pacf(y, ax=ax)\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3e285-2f21-413d-9c0f-49b60946df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data in the train and test set\n",
    "cutoff_test = int(len(y)* 0.9)\n",
    "y_train = y.iloc[:cutoff_test]\n",
    "y_test = y.iloc[cutoff_test:]\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583f08f-fa5b-4dd3-97f4-6d868e78d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a baseline with the average of the y_train data\n",
    "y_train_mean = y_train.mean()\n",
    "y_pred_baseline = [y_train_mean] * len(y_train)\n",
    "mae_baseline = mean_absolute_error(y_train, y_pred_baseline)\n",
    "\n",
    "print(\"Mean P2 Reading:\", y_train_mean)\n",
    "print(\"Baseline MAE:\", mae_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f1f20-c5ce-45f6-87e2-e9ddeb2bdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to build and calculate our model with ARIMA \n",
    "# (as I will set the I and the MA to 0, it will be an ARMA model) to speed up the process, it will be an AR model\n",
    "# Create range to test different lags\n",
    "p_params = range(1, 31)\n",
    "\n",
    "# Create empty list to hold mean absolute error scores\n",
    "maes = []\n",
    "\n",
    "# Iterate through all values of p in `p_params`\n",
    "for p in p_params:\n",
    "    \n",
    "    order = (p, 0)\n",
    "    \n",
    "    # Build model\n",
    "    model = AutoReg(y_train, lags=p).fit()\n",
    "    \n",
    "    # starting the time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # time elapsed\n",
    "    elapsed_time = round(time.time() - start_time, 2)\n",
    "    print(f\"Trained AR MODEL {order}, in {elapsed_time} seconds\")\n",
    "\n",
    "    # Make predictions on training data, dropping null values caused by lag\n",
    "    y_pred = model.predict().dropna()\n",
    "\n",
    "    # Calculate mean absolute error for training data vs predictions\n",
    "    mae = mean_absolute_error(y_train.iloc[p:], y_pred)\n",
    "\n",
    "    # Append `mae` to list `maes`\n",
    "    maes.append(mae)\n",
    "\n",
    "# Put list `maes` into Series with index `p_params`\n",
    "mae_series = pd.Series(maes, name=\"mae\", index=p_params)\n",
    "\n",
    "# Inspect head of Series\n",
    "mae_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf481b6b-2509-4bfd-9283-51ae4922095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the different errors of the models, to check which one performs better\n",
    "print(mae_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ffee8-9a2e-400d-a589-46f3bd534416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be some tradeoff between the lowest MAE and the lower number of lags that we can have,\n",
    "# so I decide that the one with 26 is the best performing model\n",
    "best_p = 26\n",
    "best_model = AutoReg(y_train, lags=best_p).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33019723-4ff2-4a2a-8ddd-7205e5cd22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LetÂ´s check the residuals from the model\n",
    "y_train_resid = model.resid\n",
    "y_train_resid.name = \"residuals\"\n",
    "y_train_resid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5407f-2bb2-4d1e-9ed6-cacd9d72bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the histogram of the residuals\n",
    "y_train_resid.hist()\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Best Model, Training Residuals\");\n",
    "# They follow more or less a normal distribution, so they are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c847a4-64e0-4266-a613-1dd73aa57673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's check the autocorrelation of the residuals\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_acf(y_train_resid, ax=ax)\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.title(\"Dar es Salaam, Training Residuals ACF\");\n",
    "# They are perfectly fine (no autocorreation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2b45c-416b-4e1a-907a-6d658fd52ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we have calculated a good time series model, let's do some predictions using the command \"forecast\"\n",
    "y_pred_wfv = pd.Series()\n",
    "history = y_train.copy()\n",
    "for i in range(len(y_test)):\n",
    "    model = AutoReg(history, lags=best_p).fit()\n",
    "    next_pred = model.forecast()\n",
    "    y_pred_wfv = y_pred_wfv.append(next_pred)\n",
    "    history = history.append(y_test[next_pred.index])\n",
    "y_pred_wfv.name = \"prediction\"\n",
    "y_pred_wfv.index.name = \"timestamp\"\n",
    "y_pred_wfv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55ec77-4526-4c67-a8a7-6391b6928038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At last, let's compare the original series with the prediction\n",
    "df_pred_test = pd.DataFrame({\"y_test\": y_test, \"y_pred_wfv\": y_pred_wfv})\n",
    "fig = px.line(df_pred_test, labels={\"value\": \"PM2.5\"})\n",
    "fig.update_layout(\n",
    "    title=\"Dar es Salaam, WFV Predictions\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"PM2.5 Level\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
